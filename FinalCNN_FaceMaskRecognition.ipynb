{"cells":[{"cell_type":"markdown","metadata":{"id":"D61PSAg07AGG"},"source":["# Face Cover Detection\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":438},"executionInfo":{"elapsed":32137,"status":"error","timestamp":1622483341776,"user":{"displayName":"Matteo Ginesi","photoUrl":"","userId":"16782441487709744510"},"user_tz":-120},"id":"GnnMy4LDvldZ","outputId":"93195fc3-7860-437b-8c6a-850fb95306d8"},"outputs":[],"source":["# Google colab loading phase\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n"," \n","from zipfile import ZipFile\n","from tqdm import tqdm\n"," \n","with ZipFile(file='/content/gdrive/MyDrive/new_data.zip') as zip_file:\n","    for file in tqdm(iterable=zip_file.namelist(), total=len(zip_file.namelist())):\n","        zip_file.extract(member=file)\n","print(' :: Unzip done.\\n')"]},{"cell_type":"markdown","metadata":{"id":"RMvte9YmzOQ4"},"source":["# Standard import"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"16KWJor044y7"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","from torch import nn\n","from torch import optim\n","from torchvision import datasets, transforms, models\n","from torch.utils.data.sampler import SubsetRandomSampler\n","from PIL import Image\n","import warnings\n","from tqdm import tqdm\n","from torch import Tensor\n","from torch.nn import functional\n","import time\n","import sys\n","from sklearn.metrics import confusion_matrix, classification_report\n","import seaborn as sn\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{"id":"v5JyLHdHqhun"},"source":["# Time format function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mCrNHzYdqkQm"},"outputs":[],"source":["def format_seconds_to_hhmmss(seconds):\n","    hours = seconds // (60*60)\n","    seconds %= (60*60)\n","    minutes = seconds // 60\n","    seconds %= 60\n","    return \"%02i:%02i:%02i\" % (hours, minutes, seconds)"]},{"cell_type":"markdown","metadata":{"id":"wnOM8ywHzSak"},"source":["# Basic parameters for training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7iY4fv2D49uL"},"outputs":[],"source":["DATA_DIR = 'new_data'\n","BATCH_SIZE = 128  # 256\n","NUM_WORKERS = 128  # 12\n","RESIZE_PARAM = 32  # 256\n","EPOCHS = 240\n","MODEL_NAME = 'FaceMaskDetectorCNN'  # 'ResNet50'\n","LEARNING_RATE = 0.001  # 0.0005\n","\n","SAVE_MODEL_NAME = MODEL_NAME + '_rp' + str(RESIZE_PARAM) + '_e' + str(EPOCHS) + '_lr' + str(LEARNING_RATE)\n","\n","warnings.filterwarnings('ignore')\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print('PyTorch device in use: ', device)"]},{"cell_type":"markdown","metadata":{"id":"CCQDYoHHzYkX"},"source":["# Our CNN custom"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"65Ch7odr4_hL"},"outputs":[],"source":["class FaceMaskDetectorCNN(nn.Module):\n","    def __init__(self):\n","        super(FaceMaskDetectorCNN, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n","        self.fc1 = nn.Linear(8 * 8 * 8, RESIZE_PARAM)\n","        self.fc2 = nn.Linear(RESIZE_PARAM, 3)\n","\n","    def forward(self, x: Tensor):\n","        \"\"\" forward pass\n","        \"\"\"\n","        out = functional.max_pool2d(torch.tanh(self.conv1(x)), 2)\n","        out = functional.max_pool2d(torch.tanh(self.conv2(out)), 2)\n","        out = out.view(-1, 8 * 8 * 8)\n","        out = torch.tanh(self.fc1(out))\n","        out = self.fc2(out)\n","        return out"]},{"cell_type":"markdown","metadata":{"id":"dvKPSVN-zgTF"},"source":["# Loader transformations and splitting functions definition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GErlF39D5BQi"},"outputs":[],"source":["def custom_loader(path):\n","    with open(path, 'rb') as f:\n","        img = Image.open(f)\n","        return img.convert('RGB')\n","\n","\n","train_transforms = transforms.Compose([\n","    transforms.RandomResizedCrop(RESIZE_PARAM),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","test_transforms = transforms.Compose([\n","    transforms.Resize(RESIZE_PARAM),\n","    transforms.CenterCrop(RESIZE_PARAM),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","\n","def load_split_train_test(datadir, valid_size=.2):\n","    train_data = datasets.ImageFolder(\n","        datadir,\n","        transform=train_transforms,\n","        loader=custom_loader)\n","    test_data = datasets.ImageFolder(\n","        datadir,\n","        transform=test_transforms,\n","        loader=custom_loader)\n","\n","    num_train = len(train_data)\n","    indices = list(range(num_train))\n","    split = int(np.floor(valid_size * num_train))\n","    np.random.shuffle(indices)\n","\n","    train_idx, test_idx = indices[split:], indices[:split]\n","    train_sampler = SubsetRandomSampler(train_idx)\n","    test_sampler = SubsetRandomSampler(test_idx)\n","    \n","    trainloader = torch.utils.data.DataLoader(\n","        train_data,\n","        sampler=train_sampler,\n","        batch_size=BATCH_SIZE,\n","        pin_memory=True)\n","    testloader = torch.utils.data.DataLoader(\n","        test_data,\n","        sampler=test_sampler,\n","        batch_size=BATCH_SIZE,\n","        pin_memory=True)\n","    \n","    return trainloader, testloader\n","\n","\n","trainloader, testloader = load_split_train_test(DATA_DIR, .3)\n","classes = trainloader.dataset.classes\n","print(classes)\n"]},{"cell_type":"markdown","metadata":{"id":"GdJM4o6ozp-C"},"source":["# Model choice and parameter definitions, parallelism if enabled"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oAPmOp3_5DtM"},"outputs":[],"source":["if MODEL_NAME == 'ResNet50':\n","    model = models.resnet50(pretrained=True)\n","    # model.to(device)\n","    # print(model)\n","\n","    for param in model.parameters():\n","        param.requires_grad = False\n","\n","    model.fc = nn.Sequential(\n","        nn.Linear(2048, 512),\n","        nn.ReLU(),\n","        nn.Dropout(0.2),\n","        nn.Linear(512, 10),\n","        nn.LogSoftmax(dim=1))\n","\n","    criterion = nn.NLLLoss()\n","    optimizer = optim.Adam(model.fc.parameters(), lr=LEARNING_RATE)\n","    # model.to(device)\n","elif MODEL_NAME == 'FaceMaskDetectorCNN':\n","    model = FaceMaskDetectorCNN()\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","    # model.to(device)\n","\n","if torch.cuda.device_count() > 1:\n","    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n","    model = nn.DataParallel(model)\n","model.to(device)\n","\n","print(model)\n","from torchsummary import summary\n","summary(model, (3, RESIZE_PARAM, RESIZE_PARAM))"]},{"cell_type":"markdown","metadata":{"id":"_06JQBGWcsBI"},"source":["# Confusion matrix and other metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KjzPESdtcu2X"},"outputs":[],"source":["def get_metrics(testloader, model, classes):\n","    print(\"\\n :: Evaluation of the model and performance report...\\n\")\n","    y_pred = []\n","    y_true = []\n","\n","    # iterate over test data\n","    for inputs, labels in tqdm(testloader):\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","        output = model(inputs)  # Feed Network\n","\n","        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n","        y_pred.extend(output)  # Save Prediction\n","\n","        labels = labels.data.cpu().numpy()\n","        y_true.extend(labels)  # Save Truth\n","\n","    # Build confusion matrix\n","    cf_matrix = confusion_matrix(y_true, y_pred)\n","    df_cm = pd.DataFrame(\n","        cf_matrix / np.sum(cf_matrix) * 10,\n","        index=[i for i in classes],\n","        columns=[i for i in classes])\n","    plt.figure(figsize=(12, 7))\n","    sn.heatmap(df_cm, annot=True)\n","    plt.savefig(SAVE_MODEL_NAME + '_matrix.png')\n","    plt.savefig('/content/gdrive/MyDrive/' + SAVE_MODEL_NAME + '_matrix.png')\n","\n","    report = classification_report(y_true, y_pred, target_names=classes)\n","    print(report)\n","\n","    # Writing data to file\n","    f = open(SAVE_MODEL_NAME + '_info.txt', 'w')\n","    f.write('Total train + eval time: ' + format_seconds_to_hhmmss(time_elapsed))\n","    f.write('\\nBatch size: ' + str(BATCH_SIZE))\n","    f.write('\\nWorkers: ' + str(NUM_WORKERS))\n","    f.write('\\nResize param: ' + str(RESIZE_PARAM))\n","    f.write('\\nEpochs: ' + str(EPOCHS))\n","    f.write('\\nLearning rate: ' + str(LEARNING_RATE))\n","    f.write('\\nModel: ' + str(MODEL_NAME))\n","    f.write('\\nMetrics report:\\n')\n","    f.write(report)\n","    f.close()\n","\n","    # Writing data to file\n","    f = open('/content/gdrive/MyDrive/' + SAVE_MODEL_NAME + '_info.txt', 'w')\n","    f.write('Total train + eval time: ' + format_seconds_to_hhmmss(time_elapsed))\n","    f.write('\\nBatch size: ' + str(BATCH_SIZE))\n","    f.write('\\nWorkers: ' + str(NUM_WORKERS))\n","    f.write('\\nResize param: ' + str(RESIZE_PARAM))\n","    f.write('\\nEpochs: ' + str(EPOCHS))\n","    f.write('\\nLearning rate: ' + str(LEARNING_RATE))\n","    f.write('\\nModel: ' + str(MODEL_NAME))\n","    f.write('\\nMetrics report:\\n')\n","    f.write(report)\n","    f.close()\n"]},{"cell_type":"markdown","metadata":{"id":"Op1025jwzyQb"},"source":["# Training phase"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7DazT5QW5Foo"},"outputs":[],"source":["epochs = EPOCHS\n","steps = 0\n","running_loss = 0\n","print_every = 10\n","train_losses, test_losses = [], []\n","total_accuracy = []\n","graph_training_loss, graph_valid_loss, graph_acc = [], [], []\n"," \n","print(' :: Training phase...', end='\\n')\n","sys.stdout.flush()\n","print('Epochs: {}, evaluation at every {} batch items'.format(\n","    epochs, print_every), end='\\n')\n","sys.stdout.flush()\n"," \n","since = time.time()\n","for epoch in range(epochs):\n","    train_eval_time = time.time()\n","    for inputs, labels in tqdm(trainloader):\n","        steps += 1\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","        logps = model.forward(inputs)\n","        loss = criterion(logps, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n"," \n","        if steps % print_every == 0:\n","            test_loss = 0\n","            accuracy = 0\n","            model.eval()\n","\n","            predictions, targets = [], []\n","            with torch.no_grad():\n","                for inputs, labels in testloader:\n","                    inputs = inputs.to(device)\n","                    labels = labels.to(device)\n"," \n","                logps = model.forward(inputs)\n","                batch_loss = criterion(logps, labels)\n","                test_loss += batch_loss.item()\n"," \n","                ps = torch.exp(logps)\n","                top_p, top_class = ps.topk(1, dim=1)\n","                equals = top_class == labels.view(*top_class.shape)\n","                accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n","                total_accuracy.append(accuracy)\n","                \n","                for i in range(len(equals)):\n","                    predictions.append(equals[i].cpu())\n","                    targets.append(labels[i].cpu())\n"," \n","            train_losses.append(running_loss / len(trainloader))\n","            test_losses.append(test_loss / len(testloader))\n","            \"\"\"\n","            print(f\"\\nTest evaluation: Epoch {epoch + 1}/{epochs}\\t\"\n","                    f\"Train loss: {running_loss / print_every:.3f}\\t \"\n","                    f\"Test loss: {test_loss / len(testloader):.3f}\\t \"\n","                    f\"Test accuracy: {accuracy / len(testloader):.3f}\")\n","            \"\"\"\n","            running_loss = 0\n","            model.train()\n"," \n","    time_elapsed = time.time() - train_eval_time\n","    print('\\nEpoch: {}/{} '.format(\n","        epoch, epochs) + ' in ' + format_seconds_to_hhmmss(time_elapsed))\n","    print('Training loss: {:.4f} Test loss: {:.4f} Accuracy: {:.4f}'.format(\n","        sum(test_losses) / len(test_losses),\n","        sum(train_losses) / len(train_losses),\n","        sum(total_accuracy) / len(total_accuracy)\n","    ))\n","    graph_valid_loss.append(sum(test_losses) / len(test_losses))\n","    graph_training_loss.append(sum(train_losses) / len(train_losses))\n","    graph_acc.append(sum(total_accuracy) / len(total_accuracy))\n","    #graph_acc.append(max(total_accuracy))\n","\n","    sys.stdout.flush()\n"," \n","time_elapsed = time.time() - since\n","print('\\n :: Training complete in ' + format_seconds_to_hhmmss(time_elapsed))\n"," \n","torch.save(model, SAVE_MODEL_NAME + '.pth')\n","torch.save(model, '/content/gdrive/MyDrive/' + SAVE_MODEL_NAME + '.pth')\n","\n","plt.plot(graph_training_loss, label='Training loss')\n","plt.plot(graph_valid_loss, label='Validation loss')\n","plt.legend(frameon=False)\n","plt.savefig(SAVE_MODEL_NAME + '_losses.png')\n","plt.savefig('/content/gdrive/MyDrive/' + SAVE_MODEL_NAME + '_losses.png')\n","plt.show()\n","\n","plt.plot(graph_acc, label='Accuracy')\n","plt.legend(frameon=False)\n","plt.savefig(SAVE_MODEL_NAME + '_accuracy.png')\n","plt.savefig('/content/gdrive/MyDrive/' + SAVE_MODEL_NAME + '_accuracy.png')\n","plt.show()\n","\n","get_metrics(testloader, model, classes)\n","\n","drive.flush_and_unmount()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Copy of FinalCNN_FaceMaskRecognition","provenance":[{"file_id":"1UY2CbjAEFPQ6Cxpj35L4_JOUnP0FJwWC","timestamp":1632815014159}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
